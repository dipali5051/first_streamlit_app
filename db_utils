
import yaml
import datetime
from sqlalchemy import create_engine, event
from pandasql import sqldf
import psycopg2
import pandas.io.sql as sqlio
import pandas as pd
import os
import time
import sys
from pandas.io.sql import SQLTable
from snowflake.snowpark import Session
from snowflake.snowpark.exceptions import SnowparkSQLException

# from data_fetcher import required_data


connection_parameters = {"account": 'ss29587.ap-southeast-1',
                            "user": 'BZ_DIPALIK',
                            "password": 'Dipali23',
                            "role": "ROLE_DEV_DE", # optional  
                            "warehouse": "WH_DEV_DBOPS", # optional    
                            "database": "DEV_CURATED", # optional     
                            "schema": "PUBLIC", # optional    
                            }


def _execute_insert(self, conn, keys, data_iter):
    print("Using monkey-patched _execute_insert")
    data = [
        (zip(keys, row)) for row in data_iter]
    conn.execute(self.table.insert().values(data))


SQLTable._execute_insert = _execute_insert


def read_sql_file(filename, folder_name, arguments):
    print(os.getcwd())
    path = './' + str(folder_name) + '/{}'.format(filename)
    fd = open(path, 'r')
    sqlFile = fd.read()
    fd.close()
    extracted_kwargs = arguments
    print(extracted_kwargs)
    return sqlFile.format(**extracted_kwargs)



def fetch_data(query, connection ):
    credentials = yaml.safe_load(
        open(
            os.path.join(
                os.getcwd(),
                'config.yaml')))
    db_credentials = credentials['databases'][connection]


    query_start_ts = time.time()
    no_result = True
    while no_result:
        try:
            session = Session.builder.configs(connection_parameters).create()
            df = pd.read_sql_query(query, session)
            # df=session.sql(query).to_pandas()
            no_result = False
        
        except SnowparkSQLException as error:
            print('There was an error with the database operation: {}'.format(error))
            session.close()
        except SnowparkSQLException as e:
            session.close()
        finally:
            session.close()
    seconds_taken = time.time() - query_start_ts
    print('Query run time in seconds : {}'.format(seconds_taken))
    return df

# result=fetch_data(query, connection )
# print (result)


    # while no_result:
    #     try:
    #         conn = psycopg2.connect(**db_credentials)
    #         df = pd.read_sql_query(query, conn)
    #         no_result = False
    #     except psycopg2.Error as error:
    #         print('There was an error with the database operation: {}'.format(error))
    #         conn.close()
    #     except exception as e:
    #         conn.close()
    #     finally:
    #         conn.close()
    # seconds_taken = time.time() - query_start_ts
    # print('Query run time in seconds : {}'.format(seconds_taken))
    # return df


def setup_connection(source):
    credentials = yaml.safe_load(open(
            os.path.join(
                os.getcwd(),
                'config.yaml')))
    if(source == "Redshift"):
        conn = psycopg2.connect(
            database=credentials['databases']['redshift_db']['database'],
            user=credentials['databases']['redshift_db']['user'],
            password=credentials['databases']['resdhift_db']['password'],
            host=credentials['databases']['redshift_db']['host'],
            port=credentials['databases']['redshift']['port'])
    elif(source == "OMS"):
        conn = psycopg2.connect(
            database=credentials['databases']['oms_db']['database'],
            user=credentials['databases']['oms_db']['user'],
            password=credentials['databases']['oms_db']['password'],
            host=credentials['databases']['oms_db']['host'],
            port=credentials['databases']['oms_db']['port'])
    else:
        raise Exception("Enter the correct source")

    return conn


def __get_sqlalchemy_engine():
    credentials = yaml.safe_load(
        open(
            os.path.join(
                os.getcwd(),
                'config.yaml')))

    database = credentials['databases']['redshift_db']['database']
    username = credentials['databases']['redshift_db']['user']
    host = credentials['databases']['redshift_db']['host']
    password = credentials['databases']['redshift_db']['password']
    port = credentials['databases']['redshift_db']['port']

    engine_query = "postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}".format(
        username=username, password=password, host=host, port=port, database=database)
    engine = create_engine(engine_query, echo=False)

    return engine


# def write_to_redshift(table_name, dataframe, engine, data_types=None):
#     dataframe.to_sql(table_name, engine, if_exists='append',
#                      chunksize=1000, index=False, dtype=data_types)


# def write_to_redshift_with_replace(
#         table_name, dataframe, engine, data_types=None):
#     dataframe.to_sql(table_name, engine, if_exists='replace',
#                      chunksize=1000, index=False, dtype=data_types)
    






def write_to_sfdb(df_dict):
    try:
        session = Session.builder.configs(connection_parameters).create()
        for table_key,df_val in df_dict.items():
            session.write_pandas(df_val, table_key, overwrite=False)

        print("data has been written into the tables.")
    
    except SnowparkSQLException as error:
            print('There was an error with the database operation: \
                {}'.format(error))
            session.close()

    except:
            print("There's an error in the dictonary.")
            
    finally:
            session.close()




#in main.py file / ur respective file
#Converting dataframe & table names into dictionary
# df_dict = {'TICKET_ISSUE_ANALYSIS_CX':tickets_data}


# #Dumping the dataframe into snowflake tables using snowpark session.
# utils.write_to_sfdb(df_dict)


    



    # def read_sql_file(filename, folder_name, arguments):
#     print(os.getcwd())
#     path = './' + str(folder_name) + '/{}'.format(filename)
#     fd = open(path, 'r')
#     sqlFile = fd.read()
#     fd.close()
#     extracted_kwargs = arguments
#     print(extracted_kwargs)
#     return sqlFile.format(**extracted_kwargs)

# print(read_sql_file('branding.sql', 'python_reports_new/Premium_Partners/queries', arguments='branding.sql'))

# def sum(a,b):
#     res=a+b
#     return res

# print(sum(2,3))


    
# print(" done")
